{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fonsmarta/Curso-QSAR/blob/main/Module1_2_2_Pandas_and_plots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a59b2543",
      "metadata": {
        "id": "a59b2543"
      },
      "source": [
        "# Machine learning methods for drug discovery and toxicology\n",
        "# Module 1.2.2: Pandas and Data Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6f496f",
      "metadata": {
        "id": "cf6f496f"
      },
      "source": [
        "In this module, we will learn how to use the Pandas python package to work with dataframes and we will do some data visualization exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "207c7cfc"
      },
      "source": [
        "# Preliminary: Preparation of the environment\n",
        "\n",
        "**Important: Remember to save a copy of this file to be able to edit it and save your changes.**\n",
        "\n",
        "Before proceeding with the exercises, we need to set up the notebook to have access to the packages and modules needed. However in this case, no additional packages will be needed as we will only work with some Python basic functions.\n"
      ],
      "id": "207c7cfc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf6df85b"
      },
      "source": [
        "\n",
        "Also, we are going to mount the google drive unit, where the course files are, so you can access it through this course.\n"
      ],
      "id": "bf6df85b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "876cdcca"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import os\n",
        "\n",
        "## Modify with the right path to the folder where all the files are going to be stored and uncomment the next line\n",
        "# if you upload your file directly, decomment next line:\n",
        "PATH = \"/content/\"\n",
        "\n",
        "# elif you use GoogleDrive, decomment next lines:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# PATH = \"/content/drive/your_folder/\""
      ],
      "id": "876cdcca"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 1: Exercises to practice with Pandas\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "THfWjg9mb3q5"
      },
      "id": "THfWjg9mb3q5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Pandas and Matplotlib\n"
      ],
      "metadata": {
        "id": "rjuwKgr4sB6h"
      },
      "id": "rjuwKgr4sB6h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this notebook we will be using two python libraries:\n",
        "\n",
        "\n",
        "*   Pandas: for dataframe handling\n",
        "*   Matplotlib: for data visualization\n",
        "\n"
      ],
      "metadata": {
        "id": "pBuQFVWzsMAU"
      },
      "id": "pBuQFVWzsMAU"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title IMPORT LIBRARIES\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# the next line is used to display the plots directly in the jupyter notebook\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "m8XSy6Gqsmtj"
      },
      "id": "m8XSy6Gqsmtj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c4d244c2",
      "metadata": {
        "id": "c4d244c2"
      },
      "source": [
        "## Section 1. Data Input and Output with Pandas: Reading and Saving DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0440839",
      "metadata": {
        "id": "e0440839"
      },
      "source": [
        "The most important role of the Pandas library is the capacity to read and save dataframes.\n",
        "\n",
        "Using the google collab sample datasets, which are localized in the folder \"sample_data\", you will practice to read and save data in different formats."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read example\n",
        "\n",
        "PATH_sample = PATH + \"sample_data/\"\n",
        "\n",
        "# read the \"california_housing_train.csv\" file\n",
        "df = pd.read_csv(PATH_sample + \"california_housing_train.csv\", sep=',')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yHXSHoG4t5Vq"
      },
      "id": "yHXSHoG4t5Vq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save example\n",
        "\n",
        "# save the dataset outside of the \"sample_data\" folder\n",
        "\n",
        "file_name = \"california_housing_train.csv\"\n",
        "\n",
        "df.to_csv(PATH + file_name)\n",
        "\n",
        "print(\"Dataframe saved as \", file_name)"
      ],
      "metadata": {
        "id": "OGcTeaFtwg4I"
      },
      "id": "OGcTeaFtwg4I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now read the original dataframe but indicate that the separator is \";\". What does the dataframe look like? Do you see the importance of a correctly indicated separator when dealing with csv files?"
      ],
      "metadata": {
        "id": "T9CW1HrBxfkr"
      },
      "id": "T9CW1HrBxfkr"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read csv exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "-BdE2IW1l3oq"
      },
      "id": "-BdE2IW1l3oq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now read california_housing_test dataframe in the \"sample_data\" folder and  save it outside of the folder as a txt file separated by tabulations (\\t)."
      ],
      "metadata": {
        "id": "glkYnrTzzl4P"
      },
      "id": "glkYnrTzzl4P"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read and save exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "kgPKoOCc5NHG"
      },
      "id": "kgPKoOCc5NHG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now save the california_housing_test dataframe as an excel file. Remember to exclude the index by indicating `index=False` when calling the function. This will avoid the accumulation of index columns throughout the data processing."
      ],
      "metadata": {
        "id": "0moRn6DE6BYt"
      },
      "id": "0moRn6DE6BYt"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save dataframe exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "utUzjHI96uq3"
      },
      "id": "utUzjHI96uq3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will be working with the \"california_housing_test.csv\" file located in the \"sample_data\" folder. Use `df.shape` to check how many rows and columns it\n",
        "has, and get the list of column names."
      ],
      "metadata": {
        "id": "9p1hr-NE8EpK"
      },
      "id": "9p1hr-NE8EpK"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataframe shape and columns exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "LqD2pI9N8OeC"
      },
      "id": "LqD2pI9N8OeC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the last 10 rows of the dataset, using the `tail` method."
      ],
      "metadata": {
        "id": "ZNOIf5i7-QTj"
      },
      "id": "ZNOIf5i7-QTj"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataframe tail exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "b8IpOjVt-dlV"
      },
      "id": "b8IpOjVt-dlV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use `df['housing_median_age'].value_counts()` to count the occurrences of unique values in the categorical column.  "
      ],
      "metadata": {
        "id": "CDLeglYA_l25"
      },
      "id": "CDLeglYA_l25"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Value_counts exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Rj62F6oP_ynJ"
      },
      "id": "Rj62F6oP_ynJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 3. Data Manipulation with Pandas: Creating, Transforming, and Combining DataFrames"
      ],
      "metadata": {
        "id": "KPHRNv3gM9ZI"
      },
      "id": "KPHRNv3gM9ZI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will continue working with the df you read in the previous task.\n",
        "\n",
        "First,  add a new column that contains the average number of rooms per houshold in each block:"
      ],
      "metadata": {
        "id": "eiikXbLfNuDl"
      },
      "id": "eiikXbLfNuDl"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Add new column example\n",
        "\n",
        "df[\"rooms_per_household\"] = df[\"total_rooms\"] / df[\"households\"]\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yQQMxgeefE-M"
      },
      "id": "yQQMxgeefE-M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the population per household and save it in a column called \"population_per_household\"."
      ],
      "metadata": {
        "id": "i41htHjGgAWH"
      },
      "id": "i41htHjGgAWH"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Add new column exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "eMn9pyGBfcU5"
      },
      "id": "eMn9pyGBfcU5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the groupby function in pandas to group your data based on one or more columns and perform operations within those groups. Here's an example of how to use groupby to calculate the average median house value for each housing median age group:"
      ],
      "metadata": {
        "id": "yoOR4kurgw_P"
      },
      "id": "yoOR4kurgw_P"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Groupby example\n",
        "\n",
        "# Group the data by 'housing_median_age' and calculate the average 'median_house_value' for each group\n",
        "age_groups = df.groupby('housing_median_age')['median_house_value'].mean().reset_index()\n",
        "\n",
        "# Print the resulting DataFrame with average median house values per housing median age group\n",
        "print(age_groups)\n"
      ],
      "metadata": {
        "id": "n6c_7MM-gzpQ"
      },
      "id": "n6c_7MM-gzpQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we used the groupby function to group the data by the 'housing_median_age' column. After grouping, we calculated the average 'median_house_value' for each group using the `mean()` function. Finally, we use `reset_index()` to reset the index of the resulting DataFrame for better readability.\n",
        "\n",
        "This gave us a new DataFrame with two columns: 'housing_median_age' and 'median_house_value'.\n",
        "\n",
        "\n",
        "Next, group the data by the 'median_income' column and calculate the average 'rooms_per_household' for each income group:"
      ],
      "metadata": {
        "id": "VD9uX-lRhJ3I"
      },
      "id": "VD9uX-lRhJ3I"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Groupby exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "# Group the data by 'median_income' and calculate the average 'rooms_per_household' for each group\n",
        "\n",
        "\n",
        "# Print the resulting DataFrame with average rooms per household per housing median income\n",
        "\n"
      ],
      "metadata": {
        "id": "-wXoxkhhinAg"
      },
      "id": "-wXoxkhhinAg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we sill use the df.loc and df.iloc to select specific rows in the dataset:"
      ],
      "metadata": {
        "id": "RluGO9VAlL9S"
      },
      "id": "RluGO9VAlL9S"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title iloc and loc examples\n",
        "\n",
        "# we select the rows 0 to 4 and the columns 0 to 2\n",
        "selected_data = df.iloc[:5,:3]\n",
        "\n",
        "print(\"selected_data DataFrame: \")\n",
        "print(selected_data)\n",
        "\n",
        "# we select those rows where the value of the column 'median_income' is bigger than 6.0\n",
        "selected_income = df.loc[df['median_income']>6.0]\n",
        "\n",
        "print(\"selected_income DataFrame: \")\n",
        "print(selected_income)"
      ],
      "metadata": {
        "id": "WzgXjwfGldeU"
      },
      "id": "WzgXjwfGldeU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now select the rows where the 'rooms_per_household' is bigger than 5 and select only the latitude and longitude columns."
      ],
      "metadata": {
        "id": "beK4MxhsmrqW"
      },
      "id": "beK4MxhsmrqW"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title loc exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "# Select rows where 'rooms_per_household' is greater than 5\n",
        "\n",
        "\n",
        "# Select only the 'latitude' and 'longitude' columns from the selected rows\n",
        "\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "po720yKtnS61"
      },
      "id": "po720yKtnS61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we extract a specific column ('median_house_value') as a Series and calculate the mean and standard deviation:"
      ],
      "metadata": {
        "id": "JkGnov_en3Bj"
      },
      "id": "JkGnov_en3Bj"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Series example\n",
        "\n",
        "# Get the series from median_house_value column\n",
        "median_house_value_series = df['median_house_value']\n",
        "\n",
        "# Calculate the mean and standard deviation\n",
        "mean_house_value = median_house_value_series.mean()\n",
        "std_house_value = median_house_value_series.std()\n",
        "\n",
        "# Print the results\n",
        "print(\"Mean house value: \", mean_house_value)\n",
        "print(\"Standard Deviation house value: \", mean_house_value)"
      ],
      "metadata": {
        "id": "4J4iy_3xoH6T"
      },
      "id": "4J4iy_3xoH6T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract each column from the two-column dataset created in the previous exercise and print the maximum and minimum value for each:"
      ],
      "metadata": {
        "id": "6JMKqlmMpRFb"
      },
      "id": "6JMKqlmMpRFb"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Series exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "# Get the series from latitude column\n",
        "\n",
        "# Get the series from longitude column\n",
        "\n",
        "# Calculate the min and max of each series\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Print the results\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iw500jTcpqkR"
      },
      "id": "iw500jTcpqkR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we split 'df' into two DataFrames: one called 'new_houses' containing rows where 'house_median_age' is less or equal to 5 and another called 'old_houses' containing ows where 'house_median_age' is greater than 50. Then we join them in a new dataset called 'house_age_extremes':"
      ],
      "metadata": {
        "id": "xCjHifrMs4WN"
      },
      "id": "xCjHifrMs4WN"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Concat example\n",
        "\n",
        "# Split the data into two DataFrames: 'new_houses' and 'old_houses'\n",
        "new_houses = df[df['housing_median_age'] <= 5]\n",
        "old_houses = df[df['housing_median_age'] > 50]\n",
        "\n",
        "# Use pd.concat to join the two DataFrames into a new DataFrame 'house_age_extremes'\n",
        "house_age_extremes = pd.concat([new_houses, old_houses])\n",
        "\n",
        "# Print the resulting DataFrame 'house_age_extremes'\n",
        "print(house_age_extremes)"
      ],
      "metadata": {
        "id": "B3bWjpj_yhWp"
      },
      "id": "B3bWjpj_yhWp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the house_age_extremes DataFrame and split it into two DataFrames: one called 'high_income' containing rows where 'median_income' is greater than or equal to 6.0, and another called 'low_income' containing rows where 'median_income' is less than 2.0."
      ],
      "metadata": {
        "id": "OvorM8_cyrdg"
      },
      "id": "OvorM8_cyrdg"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Concat exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "# Split the data into two DataFrames: 'high_income' and 'low_income'\n",
        "\n",
        "\n",
        "# Use pd.concat to join the two DataFrames into a new DataFrame 'income_extremes'\n",
        "\n",
        "\n",
        "# Print the resulting DataFrame 'income_extremes'\n",
        "\n"
      ],
      "metadata": {
        "id": "2_kMqXdNyrxm"
      },
      "id": "2_kMqXdNyrxm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's say you want to calculate the total bedrooms per household for each row in the dataset. You can use the apply function to apply a custom function for each row:"
      ],
      "metadata": {
        "id": "-gKylrpM22QE"
      },
      "id": "-gKylrpM22QE"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply example\n",
        "\n",
        "# Define a custom function to calculate total bedrooms per household for a row\n",
        "def calculate_total_bedrooms_per_household(row):\n",
        "    return row['total_bedrooms'] / row['households']\n",
        "\n",
        "# Use apply to apply the custom function to each row and create a new column\n",
        "df['avg_total_bedrooms_per_household'] = df.apply(calculate_total_bedrooms_per_household, axis=1)\n",
        "\n",
        "# Print the DataFrame with the new column\n",
        "print(df[['total_bedrooms', 'households', 'avg_total_bedrooms_per_household']])"
      ],
      "metadata": {
        "id": "v5hOIdZs3LgE"
      },
      "id": "v5hOIdZs3LgE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building on our previous example of applying an external function using apply, let's explore the power of using apply with lambda functions. Lambda functions are a concise way to create small, one-time functions on the fly. In this example, we'll use a lambda function within the apply method to calculate a new column, the 'income_to_age_ratio,' by dividing 'median_income' by 'housing_median_age' for each row in our dataset. This illustrates how we can apply dynamic transformations efficiently to our data using the combined strength of apply and lambda functions."
      ],
      "metadata": {
        "id": "6_OaarpP7dSu"
      },
      "id": "6_OaarpP7dSu"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply and lambda example\n",
        "\n",
        "# Use apply with a lambda function to calculate the ratio of 'median_income' to 'housing_median_age'\n",
        "df['income_to_age_ratio'] = df.apply(lambda row: row['median_income'] / row['housing_median_age'], axis=1)\n",
        "\n",
        "# Print the DataFrame with the new column\n",
        "print(df[['median_income', 'housing_median_age', 'income_to_age_ratio']])"
      ],
      "metadata": {
        "id": "psoTAbM67d_d"
      },
      "id": "psoTAbM67d_d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the 'price_per_room' for each row in the California Housing dataset by dividing 'median_house_value' by 'total_rooms' using a lambda function with apply. Create a new column called 'price_per_room' to store the results."
      ],
      "metadata": {
        "id": "XoTsOPOd8AGz"
      },
      "id": "XoTsOPOd8AGz"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply and lambda exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "# Use apply with a lambda function to calculate 'price_per_room'\n",
        "\n",
        "\n",
        "# Print the DataFrame with the new 'price_per_room' column\n",
        "\n"
      ],
      "metadata": {
        "id": "KpXECskv8I5M"
      },
      "id": "KpXECskv8I5M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `apply` and a `lambda` function we can also create a new column called 'income_category' in the dataset that classifies each row as 'Low Income' if 'median_income' is less than 3.0, 'Moderate Income' if it's between 3.0 and 6.0, and 'High Income' otherwise."
      ],
      "metadata": {
        "id": "GCvs_dhm8CfQ"
      },
      "id": "GCvs_dhm8CfQ"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply and lambda to classify example\n",
        "\n",
        "# Use apply with a lambda function to create 'income_category'\n",
        "df['income_category'] = df['median_income'].apply(lambda income: 'Low Income' if income < 3.0 else ('Moderate Income' if 3.0 <= income < 6.0 else 'High Income'))\n",
        "\n",
        "# Print the DataFrame with the new 'income_category' column\n",
        "print(df[['median_income', 'income_category']])"
      ],
      "metadata": {
        "id": "4zShwlc28MOB"
      },
      "id": "4zShwlc28MOB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `apply` with a `lambda` function to create a new column called 'population_density_category' in the dataset. Classify each row as 'Low Density' if 'population_per_household' is less than 2.0, 'Moderate Density' if it's between 2.0 and 4.0, and 'High Density' otherwise."
      ],
      "metadata": {
        "id": "YJD2_pyE9IRJ"
      },
      "id": "YJD2_pyE9IRJ"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Apply and lambda to classify exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "# Use apply with a lambda function to create 'population_density_category'\n",
        "\n",
        "# Print the DataFrame with the new 'population_density_category' column\n"
      ],
      "metadata": {
        "id": "5KxkAE-C9I33"
      },
      "id": "5KxkAE-C9I33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's imagine you have an external dataset with income information data. You can use `merge` to add that new information to the dataset:"
      ],
      "metadata": {
        "id": "l-nbCXUZA4dn"
      },
      "id": "l-nbCXUZA4dn"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Merge example\n",
        "\n",
        "# Create a sample 'income_info' DataFrame with income category information\n",
        "income_info_data = {'income_category': ['Low Income', 'Moderate Income', 'High Income'],\n",
        "                    'income_description': ['Less than $30,000', '$30,000 - $60,000', 'More than $60,000']}\n",
        "income_info = pd.DataFrame(income_info_data)\n",
        "\n",
        "# Merge your California housing dataset with the 'income_info' DataFrame based on the common 'income_category' column\n",
        "merged_data = pd.merge(df, income_info, on='income_category')\n",
        "\n",
        "# Print the resulting merged DataFrame\n",
        "print(merged_data)"
      ],
      "metadata": {
        "id": "dV4E4N9cBE0F"
      },
      "id": "dV4E4N9cBE0F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the following additional dataset, merge it with your original dataset:"
      ],
      "metadata": {
        "id": "T8hspjyjLNrq"
      },
      "id": "T8hspjyjLNrq"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  DataFrame to merge example\n",
        "\n",
        "population_density_info_data = {'population_density_category': ['Low Density', 'Moderate Density', 'High Density'],\n",
        "                                'density_description': ['Sparsely populated', 'Moderately populated', 'Densely populated'],\n",
        "                                'average_household_size': [2.5, 3.0, 3.5],\n",
        "                                'average_income': [50000, 60000, 70000]}\n",
        "\n",
        "population_density_info = pd.DataFrame(population_density_info_data)"
      ],
      "metadata": {
        "id": "NovDGWZXLVyQ"
      },
      "id": "NovDGWZXLVyQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Merge exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "NM_CAmokLdBI"
      },
      "id": "NM_CAmokLdBI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2: Visualizing Data with Matplotlib"
      ],
      "metadata": {
        "id": "d0bDMaAZnEGi"
      },
      "id": "d0bDMaAZnEGi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 1. Matplotlib introduction: overview"
      ],
      "metadata": {
        "id": "0gss-FwDEd5p"
      },
      "id": "0gss-FwDEd5p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matplotlib is a powerful Python library used for creating static, animated, and interactive visualizations in various formats. It is particularly well-suited for data visualization tasks, making it an essential tool for data analysis.\n",
        "\n",
        "Matplotlib provides a wide range of functions to create different types of plots. The simplest way to create a basic plot is by using the plt.plot() function. Here's an example:"
      ],
      "metadata": {
        "id": "ooE-bQ1YEogY"
      },
      "id": "ooE-bQ1YEogY"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Simple plot with matplotlib\n",
        "\n",
        "# Sample data\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [10, 16, 8, 14, 7]\n",
        "\n",
        "# Create a line plot\n",
        "plt.plot(x, y)\n",
        "\n",
        "# Add labels and a title\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Simple Line Plot')"
      ],
      "metadata": {
        "id": "95vKJga7cq4l"
      },
      "id": "95vKJga7cq4l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Matplotlib supports various types of plots, including:\n",
        "\n",
        "\n",
        "\n",
        "*   **Line Plot**: Used to visualize data points connected by lines, as shown in the example above.\n",
        "*   **Scatter Plot**: Useful for displaying individual data points, often used for visualizing relationships between two variables.\n",
        "*   **Bar Plot**: Great for comparing data across categories or displaying categorical data.\n",
        "*   **Histogram**: Used to visualize the distribution of a single variable.\n",
        "*   **Box Plot**: Ideal for displaying the distribution, variability, and outliers of a dataset.\n",
        "*   **Pie Chart**: Good for displaying parts of a whole, where each category represents a portion of the total.\n",
        "*   **Heatmap**: Effective for displaying the correlation or intensity of data in a matrix form.\n",
        "*   **3D Plotting**: Matplotlib also supports 3D visualization for more complex data.\n",
        "\n",
        "\n",
        "Matplotlib allows for extensive customization of the plots. You can change colors, line styles, add legends, annotations, and much more. Feel free to explore the documentation and examples to discover the full range of customization options.\n",
        "\n",
        "Remember that Matplotlib is just one of many data visualization libraries available in Python, and depending on your requirements, you may explore other libraries like Seaborn, Plotly, or Bokeh for more advanced and interactive visualizations.\n",
        "\n",
        "However, to keep it simple, in this Jupyter notebook we will focus on the representation of data using bar and scatter plots, as these are the ones we will use in the process of creating a QSAR model."
      ],
      "metadata": {
        "id": "saw_mNSEcfZL"
      },
      "id": "saw_mNSEcfZL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 2. Barplots: How to represent classification data"
      ],
      "metadata": {
        "id": "Qt9gOOAin4pr"
      },
      "id": "Qt9gOOAin4pr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will read the california housing train and test datasets, and we will add a classification column to them:"
      ],
      "metadata": {
        "id": "4Rw7A-c3g8yh"
      },
      "id": "4Rw7A-c3g8yh"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read train and test sample data and make classification column\n",
        "\n",
        "df_train = pd.read_csv(PATH_sample + \"california_housing_train.csv\", sep=\",\")\n",
        "print(df_train.head())\n",
        "\n",
        "df_test = pd.read_csv(PATH_sample + \"california_housing_test.csv\", sep=\",\")\n",
        "print(df_test.head())\n",
        "\n",
        "# define a function to create the classification column\n",
        "def classify_value(value):\n",
        "  threshold = 200000\n",
        "  if value >= threshold:\n",
        "    return \"High Value\"\n",
        "  else:\n",
        "    return \"Low Value\"\n",
        "\n",
        "df_train[\"value_category\"] = df_train['median_house_value'].apply(classify_value)\n",
        "print(df_train.head())\n",
        "\n",
        "df_test[\"value_category\"] = df_test['median_house_value'].apply(classify_value)\n",
        "print(df_test.head())"
      ],
      "metadata": {
        "id": "k3mkoHtwhFYJ"
      },
      "id": "k3mkoHtwhFYJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use the value_counts to calculate the counts of \"High Value\" and \"Low Value\" samples separately for both the train and test sets.\n",
        "\n",
        "We then create a stacked barplot using Matplotlib, where \"Train\" and \"Test\" represent the datasets, and within each bar, you'll see the stacked segments for \"High Value\" (green) and \"Low Value\" (red) samples."
      ],
      "metadata": {
        "id": "TVwDNza8qKYv"
      },
      "id": "TVwDNza8qKYv"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create stacked barplot example\n",
        "\n",
        "# Calculate counts of \"High Value\" and \"Low Value\" samples in both train and test sets\n",
        "train_value_counts = df_train['value_category'].value_counts()\n",
        "test_value_counts = df_test['value_category'].value_counts()\n",
        "\n",
        "# Create a stacked barplot\n",
        "categories = ['Train', 'Test']\n",
        "high_value_counts = [train_value_counts['High Value'], test_value_counts['High Value']]\n",
        "low_value_counts = [train_value_counts['Low Value'], test_value_counts['Low Value']]\n",
        "\n",
        "# Plot each individual series\n",
        "plt.bar(categories, high_value_counts, label='High Value', color='green')\n",
        "plt.bar(categories, low_value_counts, bottom=high_value_counts, label='Low Value', color='red')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "plt.xlabel('Dataset')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Distribution of \"High Value\" and \"Low Value\" Samples in Train and Test Sets')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "v3Xm3r2ZrInj"
      },
      "id": "v3Xm3r2ZrInj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, make a stacked barplot from the 3-category classification of the income we create in the following code cell:"
      ],
      "metadata": {
        "id": "T7HC-cQBr6eZ"
      },
      "id": "T7HC-cQBr6eZ"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating new example classification column\n",
        "\n",
        "# Use apply with a lambda function to create 'income_category'\n",
        "df_train['income_category'] = df_train['median_income'].apply(lambda income: 'Low Income' if income < 3.0 else ('Moderate Income' if 3.0 <= income < 6.0 else 'High Income'))\n",
        "print(df_train.head())\n",
        "\n",
        "df_test['income_category'] = df_test['median_income'].apply(lambda income: 'Low Income' if income < 3.0 else ('Moderate Income' if 3.0 <= income < 6.0 else 'High Income'))\n",
        "print(df_test.head())\n"
      ],
      "metadata": {
        "id": "3AsaScQ8sEyt"
      },
      "id": "3AsaScQ8sEyt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Represent \"income_category\" in a stacked barplot\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "# Calculate counts of \"High Value\" and \"Low Value\" samples in both train and test sets\n",
        "\n",
        "\n",
        "\n",
        "# Create a stacked barplot\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the bottom parameter for the \"Low Income\" bars\n",
        "# Note: when giving the barplot a bottom value, take into account that it must\n",
        "# represent any categories that have been already represented\n",
        "# (maybe you'll have to sum these values).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot each individual series\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Add labels, title, and legend\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Op7319FQtOLV"
      },
      "id": "Op7319FQtOLV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Section 3. Scatter plots: How to represent regression data"
      ],
      "metadata": {
        "id": "VUwZH_MRoMEH"
      },
      "id": "VUwZH_MRoMEH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create a scatter plot using the longitude and latitude columns in the train dataset:"
      ],
      "metadata": {
        "id": "f1PnEZtO1HRV"
      },
      "id": "f1PnEZtO1HRV"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scatter plot example\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(10, 6))  # Set the figure size (adjust as needed)\n",
        "plt.scatter(df_train['longitude'], df_train['latitude'], c='blue', s=5)  # Customize the color and point size\n",
        "\n",
        "# Add labels and a title\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.title('Scatter Plot of Longitude vs. Latitude')\n",
        "\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "vYqzsq6m1orA"
      },
      "id": "vYqzsq6m1orA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you superposed this scatterplot to a California map, it would match pretty well, don't you think?\n",
        "\n",
        "Now, create a new scatter plot where the x axis is the Longitude and the y axis is the latitude, and represent the train set samples in blue and the test set samples in red:"
      ],
      "metadata": {
        "id": "z3XIB1zN2EaV"
      },
      "id": "z3XIB1zN2EaV"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scatter plot exercise\n",
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "# Create a scatter plot\n",
        "\n",
        "# Note: remember how we built the stacked barplot as if they were two different\n",
        "# barplots? You can do the same with the scatter plot :)\n",
        "\n",
        "# Add labels and a title\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r34IiJBz2Dbf"
      },
      "id": "r34IiJBz2Dbf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Creating the 'predicted_values' column\n",
        "\n",
        "# As we are not using any real machine learning model in this notebook\n",
        "# we will input some random numbers in our predicted column\n",
        "# however, we want the random numbers to be around the mean of our\n",
        "# \"median_house_value\" column values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calculate the mean of \"median_house_value\"\n",
        "mean_value = df_test[\"median_house_value\"].mean()\n",
        "\n",
        "# Generate random numbers around the median\n",
        "np.random.seed(42)  # Setting a seed for reproducibility\n",
        "std_deviation = 500000\n",
        "random_values = np.random.normal(loc=mean_value, scale=std_deviation, size=len(df))\n",
        "\n",
        "# Create the \"predicted_value\" column\n",
        "df_test['predicted_value'] = random_values\n",
        "\n",
        "print(df_test.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "F0Q-IOqb4Gu7"
      },
      "id": "F0Q-IOqb4Gu7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the median_house_value\" column as the values we observed, and the \"predicted_value\" column as the predicted values. With these columns, we will create a scatter plot.\n",
        "\n",
        "To make it easier to see how different the observed and predicted values are, we will draw a line of equality. This line is a diagonal line that shows when the two variables have the same value. The vertical and horizontal distance from the line represents the absolute difference between the groups. The diagonal distance represents half of that difference. The further the points are from the line, the greater the difference between the variables."
      ],
      "metadata": {
        "id": "qLeI7Qwq5ctn"
      },
      "id": "qLeI7Qwq5ctn"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scatter plot for OBS vs PRED example\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 8))  # Set the figure size (adjust as needed)\n",
        "plt.scatter(df_test['median_house_value'], df_test['predicted_value'], c='blue', s=60)\n",
        "\n",
        "# Add a line of equality (diagonal line)\n",
        "plt.plot([df_test['median_house_value'].min(), df_test['median_house_value'].max()],\n",
        "         [df_test['median_house_value'].min(), df_test['median_house_value'].max()],\n",
        "         linestyle='--', color='red', linewidth=2, label='Line of Equality')\n",
        "\n",
        "# Add labels and a title\n",
        "plt.xlabel('Observed Values (median_house_value)')\n",
        "plt.ylabel('Predicted Values (predicted_value)')\n",
        "plt.title('Scatter Plot of Observed vs. Predicted Values')\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Add grid lines for reference\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "XB2B0NoDQ-6a"
      },
      "id": "XB2B0NoDQ-6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Throughout this section, we have explored various data visualization techniques, using them to demonstrate how data can be effectively represented. As you progress through the course, you will encounter real-world applications of data visualization in data curation and the analysis of QSAR model performance. These examples will showcase how data visualization becomes an indispensable tool for gaining insights, making informed decisions, and enhancing the overall understanding of data across various scenarios."
      ],
      "metadata": {
        "id": "jAUKOcwFogSW"
      },
      "id": "jAUKOcwFogSW"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}